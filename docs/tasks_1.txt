
Глобальная цель: создать имитацию "взрослого" сервиса рекомендаций, используя все основные технологии Big Data, современные методологии 
и данные соревнования от H&M.

*) реализовать несколько подходов моделей рекомендаций (факторизация, реранкинг с бустингами, обычный two-tower, TwHIN)
*) создать инфраструктуру на "серьезном" Big Data стэке (Hadoop, Hive, Kafka, Redis, Spark)
*) организовать мониторинг, логирование, тестирование, CI/CD
*) задеплоить хотя бы небольшие и низконагруженные сервисы в облаке

Skills to train:
*) Логирование
*) Тестирование
*) aiohttp, asyncio, swagger
*) dvc
*) Polars
*) SQL 
*) SQL DBs (SQLite, PostgreSQL, MySQL, GreenPlum, Clickhouse)
*) NoSQL (Hive, Cassandra, MongoDB)
*) Flask, FastAPI, Django (DRF)
*) Kafka
*) Redis
*) SQLAlchemy
*) Spark
*) Hadoop
*) Airflow
*) Presto
*) Docker
*) Docker Compose
*) Kubernates
*) Деплой в облаке (Yandex Cloud)
*) ElasticSearch + Kibana
*) Solr
*) CI/CD (jenkins, github actions, gitlab)
*) Scala
*) Akka
*) pytorch (+ lightning + pytorch2 + pytorch-lifestream), tf, keras (MXNet, Sonet, JAX для общего развития)
*) Streaming, online learning
*) A/B тесты
*) Dashboards (Tableue, Dash)
?) ReckBole

baseline:
*) разделить юзеров на группы (есть/нет транзакции)
*) FAISS ALS на группе с транзакциями без учета количества купленных товаров (если купил, то просто 1)
*) генерирование N (12) кандидатов по: user_cf_embedding
*) для юзеров без транзакций - самые популярные товары
*) cv 5-fold group  validation
*) попрактиковать, посмотреть, как ведут себя различные метрики рекомендаций

upgrades:
*) попробовать не рекомендовать уже купленное
*) для холодных юзеров рекомендовать товары по RFM скору
*) учет количества купленных товаров (посмотреть, как изменится скор при рекомендациях)
*) добавить кандидатов item_cf_embedding (среднее по эмбеддингам товаров)
*) lightgbm (binary classification, pairwise)
--- Попробовать различные стратегии негативного сэмплинга кандидатов:
	*) все товары-кандидаты негативные, кроме тех, что были куплены
	*) случайная выборка из не купленных (на первый вариант может не хватить RAM)
	*) взять среднее позитивных, отранжировать кандидатов по увеличению расстояния,
	   использовать линейное (?), экспоненциальное убывание релевантности (?)
--- Проблема холодного старта:
	?) есть ли у юзеров без транзакций какие-то признаки?
	?) как решить проблему холодного старта в данной задаче?
	?) Попробовать two-tower, где используются нетранзакционные признаки юзеров и айтемов?
?) графовые сети
?) Tw-HIN
